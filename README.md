# MLX NLP Chatbot Demo

A comprehensive demonstration of Natural Language Processing (NLP) capabilities for chatbots using **Apple's MLX framework**, optimized for Apple Silicon (M1/M2/M3) Neural Processing Units (NPU).

## ðŸŽ¯ Project Overview

This project showcases three practical NLP use cases for chatbots, trained on **real-world datasets** with production-ready pipelines:

1. **Intent Classification** - Classify user commands into categories (trained on SNIPS & Banking77 datasets)
2. **Sentiment Analysis** - Detect emotions in messages (trained on IMDB movie reviews)
3. **Text Generation** - Generate responses and provide autocomplete suggestions (trained on WikiText corpus)

All models are built using MLX, leveraging the power of Apple Silicon for efficient on-device text processing. The project includes **50,000+ real training examples** with automated dataset downloading and preprocessing.

## ðŸš€ Features

### 1. Intent Classification (`intent_classifier.py`)
- Classifies user input into predefined intents
- Uses LSTM-based architecture
- **Real datasets**: SNIPS (16K+ queries), Banking77 (13K banking intents)
- **Sample data**: 9 examples for quick testing
- Interactive prediction mode with confidence scores

**Example Usage:**
```
Input: "Hello there"
â†’ Intent: greeting (confidence: 95%)

Input: "What's the weather like"
â†’ Intent: question (confidence: 92%)

Input: "Turn off the lights"
â†’ Intent: command (confidence: 88%)
```

### 2. Sentiment Analysis (`sentiment_analysis.py`)
- Detects sentiment in user messages
- Binary classification: positive, negative
- **Real dataset**: IMDB movie reviews (50K labeled reviews)
- **Sample data**: 8 reviews for quick testing
- LSTM with dropout for better generalization
- Returns confidence scores with probabilities

**Example Usage:**
```
Input: "I love this product"
â†’ Sentiment: positive
â†’ Probabilities: negative=2% neutral=5% positive=93%

Input: "This is terrible"
â†’ Sentiment: negative
â†’ Probabilities: negative=90% neutral=7% positive=3%
```

### 3. Text Generation (`text_generator.py`)
- Generates text continuations from seed text
- Provides autocomplete suggestions
- **Real dataset**: WikiText-2 (36K+ Wikipedia articles, 100M tokens)
- **Sample data**: Small corpus for quick testing
- Temperature-controlled sampling
- LSTM-based sequence-to-sequence generation

**Example Usage:**
```
Seed: "hello how are"
â†’ Generated: "hello how are you today"

Text: "thank you very"
â†’ Suggestions: much (45%), well (30%), nice (15%)
```

## ðŸ“¦ Installation

### Prerequisites
- macOS with Apple Silicon (M1/M2/M3)
- Python 3.8 or higher

### Setup

1. **Clone the repository:**
```bash

```

2. **Activate virtual environment:**
```bash
source .venv/bin/activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
# Installs: mlx, numpy, scikit-learn, datasets, jupyter, matplotlib, seaborn, plotly, wordcloud
```

## ðŸš€ Quick Start

### Option 1: Interactive Jupyter Notebooks (Recommended for Learning)

```bash
# 1. Activate the virtual environment
source .venv/bin/activate

# 2. Navigate to notebooks folder
cd notebooks

# 3. Start Jupyter
jupyter notebook
```

Open any notebook:
- **`00_Overview.ipynb`** - Quick 15-minute intro to all three techniques
- **`01_Intent_Classification.ipynb`** - 60-minute complete tutorial with theory
- **`02_Sentiment_Analysis.ipynb`** - 75-minute complete tutorial with theory
- **`03_Text_Generation.ipynb`** - 90-minute complete tutorial with theory
- **`04_Complete_Pipeline.ipynb`** - 120-minute full integration

**Each notebook is completely self-contained** with:
- âœ… Complete theory and explanations
- âœ… Working code examples
- âœ… Beautiful visualizations
- âœ… Hands-on exercises
- âœ… No external file dependencies

### Option 2: Command-Line Training

```bash
# Activate the virtual environment
source .venv/bin/activate

# Run interactive training with real datasets
python examples_with_real_data.py

# Or use standalone scripts
python train_intent_classifier.py
python production_example.py
```

### ðŸ†• Training with Real Datasets

**Quick Start with Sample Data (< 1 second):**
```bash
# Download sample datasets (9 intents, 8 sentiments, small corpus)
python scripts/download_datasets.py --samples

# Option 1: Use Jupyter notebooks (recommended)
cd notebooks
jupyter notebook
# Open 01, 02, or 03 for complete tutorials

# Option 2: Use command-line script
python examples_with_real_data.py
# Choose option 1-3 for quick tests
```

**Production Training with Real Data (10-30 seconds per dataset):**
```bash
# Download all real datasets (IMDB 50K, SNIPS 16K+, Banking77 13K, WikiText 36K)
python scripts/download_datasets.py --all

# Or download specific datasets
python scripts/download_datasets.py --imdb     # Sentiment analysis
python scripts/download_datasets.py --snips    # Intent classification
python scripts/download_datasets.py --wikitext # Text generation

# Shell script alternative
./scripts/download_datasets.sh
```

**Train Models:**
```bash
# Interactive examples with all datasets
python examples_with_real_data.py
# Options: 4=IMDB (25K), 5=SNIPS (16K+), 6=Complete pipeline

# Standalone training scripts
python train_intent_classifier.py --data data/snips --epochs 40

# Full production pipeline with experiment tracking
python production_example.py
```

**Available Datasets:**
- **IMDB**: 50K movie reviews (sentiment)
- **SNIPS**: 16K+ voice assistant queries (7 intents)
- **Banking77**: 13K banking queries (77 intents)
- **WikiText-2**: 36K articles, 100M tokens (generation)

**See [TRAINING_GUIDE.md](TRAINING_GUIDE.md) for complete instructions and benchmarks**

### Option 1: Run All Demos
```bash
python main.py
```
This launches an interactive menu where you can select individual demos or run all of them.

### Option 2: Run Specific Demos

**Command-line shortcuts:**
```bash
# Intent Classification
python main.py 1
# or
python main.py intent

# Sentiment Analysis
python main.py 2
# or
python main.py sentiment

# Text Generation
python main.py 3
# or
python main.py text

# Run all demos
python main.py 4
# or
python main.py all
```

**Direct execution:**
```bash
# Intent Classification
python intent_classifier.py

# Sentiment Analysis
python sentiment_analysis.py

# Text Generation
python text_generator.py

# Programmatic examples
python examples.py
```

## ðŸ“ Project Structure

```
apple-mlx-test/
â”œâ”€â”€ .venv/                           # Virtual environment
â”œâ”€â”€ notebooks/                       # ðŸ““ All-in-one learning notebooks
â”‚   â”œâ”€â”€ mlx_nlp_utils.py             # Consolidated model code (300+ lines)
â”‚   â”œâ”€â”€ README.md                    # Notebooks guide
â”‚   â”œâ”€â”€ 00_Overview.ipynb            # Quick intro & demos (15 min)
â”‚   â”œâ”€â”€ 01_Intent_Classification.ipynb    # Complete tutorial (60 min)
â”‚   â”œâ”€â”€ 02_Sentiment_Analysis.ipynb       # Complete tutorial (75 min)
â”‚   â”œâ”€â”€ 03_Text_Generation.ipynb          # Complete tutorial (90 min)
â”‚   â””â”€â”€ 04_Complete_Pipeline.ipynb        # Full integration (120 min)
â”œâ”€â”€ data/                            # Datasets directory
â”‚   â”œâ”€â”€ intent_samples/              # Sample intent data (9 examples)
â”‚   â”œâ”€â”€ sentiment_samples/           # Sample sentiment data (8 reviews)
â”‚   â”œâ”€â”€ text_gen_samples/            # Sample text corpus
â”‚   â”œâ”€â”€ imdb/                        # IMDB movie reviews (50K)
â”‚   â”œâ”€â”€ snips/                       # SNIPS intents (16K+)
â”‚   â”œâ”€â”€ banking77/                   # Banking77 intents (13K)
â”‚   â””â”€â”€ wikitext/                    # WikiText corpus (36K articles)
â”œâ”€â”€ scripts/                         # Utility scripts
â”‚   â”œâ”€â”€ download_datasets.py         # Dataset downloader (Python)
â”‚   â””â”€â”€ download_datasets.sh         # Dataset downloader (Shell)
â”œâ”€â”€ trained_models/                  # Saved model checkpoints
â”œâ”€â”€ examples_with_real_data.py       # Interactive real dataset training
â”œâ”€â”€ train_intent_classifier.py       # Standalone training script
â”œâ”€â”€ production_example.py            # Production pipeline (650 lines)
â”œâ”€â”€ TRAINING_GUIDE.md                # Complete training documentation
â”œâ”€â”€ CONSOLIDATION_COMPLETE.md        # ðŸ†• Consolidation details
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ README.md                        # This file
```

**Note:** All Python code and documentation have been consolidated into the Jupyter notebooks for easier learning and demonstration. The notebooks are now completely self-contained with theory, code, and visualizations in one place.

## ðŸ”§ Technical Details

### Programmatic Usage

All models can be imported and used in your own code. See `examples.py` for comprehensive examples:

```python
from intent_classifier import IntentClassifier, prepare_data, train_model, predict_intent

# Prepare data and train
X, y, vocab, _, intent_names = prepare_data()
model = IntentClassifier(len(vocab), 32, 64, len(intent_names))
model = train_model(model, X, y, epochs=50)

# Use the model
intent, confidence = predict_intent(model, "Hello there", vocab, intent_names, max_len)
print(f"Intent: {intent} ({confidence:.2%})")
```

Run `python examples.py` to see complete examples including:
- Individual model usage
- Combining multiple models
- Building a complete chatbot pipeline

### Model Architectures

**Intent Classifier:**
- Embedding dimension: 32
- LSTM hidden size: 64
- 3 output classes
- Training: 50 epochs with SGD

**Sentiment Analyzer:**
- Embedding dimension: 64
- LSTM hidden size: 128
- Dropout: 0.3
- 3 output classes
- Training: 100 epochs with Adam

**Text Generator:**
- Embedding dimension: 128
- LSTM hidden size: 256
- Sequence length: 5 words
- Training: 200 epochs with Adam

### MLX Framework Benefits

- **Native Apple Silicon support** - Runs on M1/M2/M3 NPU
- **Efficient memory usage** - Optimized for unified memory architecture
- **Low latency** - On-device inference without cloud dependency
- **Familiar API** - NumPy-like interface with PyTorch-style modules

## ðŸŽ¯ Use Cases

### For Chatbots
1. **Intent Classification** - Route user queries to appropriate handlers
2. **Sentiment Analysis** - Adjust tone of responses based on user emotion
3. **Text Generation** - Provide smart autocomplete and response suggestions

### For Production
- Combine with Core ML for deployment in iOS/macOS apps
- Fine-tune models on domain-specific data
- Extend with more intents, sentiments, or training data

## ðŸ”„ Next Steps

### Expand Functionality
- Add Named Entity Recognition (NER) for extracting entities
- Implement question-answering with FAQ matching
- Add multilingual support with translation models
- Fine-tune on domain-specific datasets (customer support, medical, legal)

### Improve Models
- âœ… **Done**: Training on real datasets (IMDB, SNIPS, Banking77, WikiText)
- Experiment with Transformer architectures (attention mechanisms)
- Add beam search for better text generation
- Implement model ensembling for better accuracy

### Production Deployment
- âœ… **Done**: Production pipeline with experiment tracking
- âœ… **Done**: Data cleaning and preprocessing pipelines
- Convert models to Core ML format
- Build iOS/macOS app interface
- Add model versioning and A/B testing
- Deploy REST API with FastAPI/Flask

## ðŸ“ Example Training Output

```
==================================================
MLX Intent Classification Demo
==================================================

Vocabulary size: 42
Number of intents: 3
Intents: ['command', 'greeting', 'question']
Training samples: 30

Training Intent Classifier...
--------------------------------------------------
Epoch 10/50 - Loss: 0.8234 - Accuracy: 0.6667
Epoch 20/50 - Loss: 0.4521 - Accuracy: 0.8333
Epoch 30/50 - Loss: 0.2341 - Accuracy: 0.9333
Epoch 40/50 - Loss: 0.1234 - Accuracy: 0.9667
Epoch 50/50 - Loss: 0.0823 - Accuracy: 1.0000
--------------------------------------------------
```

## ðŸ¤ Contributing

Feel free to extend this project with:
- Additional NLP tasks (NER, question-answering, etc.)
- Larger/better training datasets
- Different model architectures (Transformers, CNNs)
- Performance benchmarks
- iOS/macOS app integration

## ðŸ“– Educational Resources

**ðŸŽ“ Three ways to learn - pick your style!**

### 1. ðŸ““ Interactive Notebooks (Recommended for Beginners)
**Visual, hands-on learning with 20+ types of visualizations:**
- **[notebooks/00_Overview.ipynb](notebooks/00_Overview.ipynb)** - Quick intro with demos of all 3 techniques
- **[notebooks/01_Intent_Classification.ipynb](notebooks/01_Intent_Classification.ipynb)** - Full tutorial with training curves, confusion matrices
- **[notebooks/02_Sentiment_Analysis.ipynb](notebooks/02_Sentiment_Analysis.ipynb)** - Coming soon! Word clouds, ROC curves
- **[notebooks/03_Text_Generation.ipynb](notebooks/03_Text_Generation.ipynb)** - Coming soon! Perplexity, temperature comparison
- **[notebooks/04_Complete_Pipeline.ipynb](notebooks/04_Complete_Pipeline.ipynb)** - Coming soon! End-to-end chatbot

**ðŸ“˜ See [notebooks/README.md](notebooks/README.md)** for learning paths, installation, and expected results.

### 2. ðŸ“š Comprehensive Documentation (6,600+ lines)

#### Quick Start with Production Data
- **[TRAINING_GUIDE.md](TRAINING_GUIDE.md)** - ðŸ†• Complete guide to training with real datasets
- **[REAL_DATA_SUMMARY.txt](REAL_DATA_SUMMARY.txt)** - ðŸ†• Overview of all dataset features
- **[PRODUCTION_README.md](PRODUCTION_README.md)** - Real-world datasets (IMDB, SNIPS, Banking77, WikiText)
- **[production_example.py](production_example.py)** - Complete production pipeline (650 lines)
- **[examples_with_real_data.py](examples_with_real_data.py)** - ðŸ†• Interactive examples (6 scenarios)

#### Learning Guides (in `/docs` folder)

| Guide | Topics | Difficulty | Time |
|-------|--------|-----------|------|
| **[Datasets & Preprocessing](docs/DATASETS_AND_PREPROCESSING.md)** | Real datasets, cleaning, tokenization | â­â­ Intermediate | 60 min |
| **[Production Best Practices](docs/PRODUCTION_BEST_PRACTICES.md)** | Deployment, monitoring, security | â­â­â­ Advanced | 45 min |
| **[MLX Framework](docs/MLX_FRAMEWORK_GUIDE.md)** | Apple Silicon, arrays, optimization | â­ Beginner | 30 min |
| **[Intent Classification](docs/INTENT_CLASSIFICATION_GUIDE.md)** | Command routing, embeddings, LSTM | â­ Beginner | 45 min |
| **[Sentiment Analysis](docs/SENTIMENT_ANALYSIS_GUIDE.md)** | Emotion detection, dropout, context | â­â­ Intermediate | 60 min |
| **[Text Generation](docs/TEXT_GENERATION_GUIDE.md)** | Autocomplete, sampling, temperature | â­â­â­ Advanced | 90 min |

### What's Inside Each Guide

âœ… **Conceptual explanations** with real-world analogies  
âœ… **Architecture deep dives** - layer-by-layer breakdowns  
âœ… **Training process** - loss functions, optimization, gradients  
âœ… **Production pipelines** - real datasets, cleaning, deployment  
âœ… **Practical examples** - working code you can run  
âœ… **Use cases** - real-world applications  
âœ… **Exercises** - beginner, intermediate, and advanced  
âœ… **Advanced topics** - attention, transformers, deployment  
âœ… **Troubleshooting** - common issues and solutions  

### 3. ðŸƒ Hands-on Code Examples
**Interactive scripts you can run and modify:**
- `examples_with_real_data.py` - 6 real dataset scenarios (10K-50K samples each)
- `quick_demo.py` - Fast demonstration with sample data
- `examples.py` - Code examples you can copy and adapt
- `production_example.py` - Full production pipeline (650 lines)

### Learning Path Recommendations

**ðŸ”° Total Beginner? (6 hours)**
1. Start with **notebooks/00_Overview.ipynb** (15 min) - Visual introduction to all three tasks
2. Work through **notebooks/01_Intent_Classification.ipynb** (60 min) - Complete tutorial with theory
3. Continue with **notebooks/02_Sentiment_Analysis.ipynb** (75 min) - Build on classification
4. Explore **notebooks/03_Text_Generation.ipynb** (90 min) - Most advanced technique
5. Finish with **notebooks/04_Complete_Pipeline.ipynb** (120 min) - Full integration

**Each notebook is 100% self-contained** - no jumping between files!

**ðŸŽ¯ Want Production Skills?**
1. Complete the notebooks above for solid foundation
2. Run **examples_with_real_data.py** with real datasets (IMDB, SNIPS, WikiText)
3. Read **TRAINING_GUIDE.md** for complete training workflows
4. Study **production_example.py** (650 lines of production code)

**ðŸš€ Advanced Developer?**
1. Jump directly to notebooks based on your interest
2. Review **production_example.py** for deployment patterns
3. Try **train_intent_classifier.py** for standalone training
4. Build your own project with **notebooks/mlx_nlp_utils.py**

**Key Resources:**
- ðŸ““ **All notebooks**: Complete theory + code + visualizations in one place
- ðŸ“– **TRAINING_GUIDE.md**: Real dataset training (IMDB 50K, SNIPS 16K, WikiText 36K)
- ðŸ’¼ **production_example.py**: 650 lines of production-ready code
- ðŸ› ï¸ **notebooks/mlx_nlp_utils.py**: Reusable model implementations

### Quick Start Guide

**For Learning:**
```bash
cd notebooks && jupyter notebook
# Open 00_Overview.ipynb
```

**For Production Training:**
```bash
python examples_with_real_data.py  # Interactive menu
# or
python train_intent_classifier.py  # Standalone training
```

**Total Learning Content:**
- 5 complete notebooks with embedded theory
- 28+ visualization types
- 50+ diagrams and examples
- Beginner through advanced exercises
- 6 hours of guided learning

## ðŸ“„ License

This project is for educational and demonstration purposes.

## ðŸ™ Acknowledgments

- Apple MLX team for the excellent framework
- Inspired by practical chatbot NLP applications
- Built with â¤ï¸ for Apple Silicon

## ðŸ“š Further Reading

- **MLX Documentation**: https://ml-explore.github.io/mlx/
- **LSTM Paper**: "Long Short-Term Memory" by Hochreiter & Schmidhuber
- **Word Embeddings**: "Efficient Estimation of Word Representations" (Word2Vec)
- **Attention**: "Neural Machine Translation by Jointly Learning to Align and Translate"

---

**Ready to explore NLP on Apple Silicon?** 

**Start learning:** `cd notebooks && jupyter notebook` (open `00_Overview.ipynb`)

**Start training:** `python examples_with_real_data.py`

ðŸš€ All code consolidated into easy-to-use notebooks - theory, code, and visualizations in one place!

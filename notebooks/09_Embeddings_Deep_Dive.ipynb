{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7df7d40",
   "metadata": {},
   "source": [
    "# Lesson 9: Embeddings Deep Dive\n",
    "\n",
    "**Prerequisites:** Complete Lesson 8 (RAG basics)\n",
    "\n",
    "**Goal:** Understand what embeddings are, how to use them, and optimize them for your use case.\n",
    "\n",
    "**Why This Matters:** Your entire RAG/memory/trace system depends on embeddings. Bad embeddings = bad retrieval = bad responses.\n",
    "\n",
    "## Overview\n",
    "\n",
    "**What you'll learn:**\n",
    "1. What embeddings actually are (not just \"vectors\")\n",
    "2. How to use real embedding models (not toy BOW)\n",
    "3. How to choose the right embedding model\n",
    "4. When to fine-tune embeddings\n",
    "5. How to optimize embeddings for specific domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96851335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "%pip install sentence-transformers scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d23d757",
   "metadata": {},
   "source": [
    "## Part 1: What Are Embeddings? (Theory + Visualization)\n",
    "\n",
    "**Embeddings = Dense vector representations of meaning**\n",
    "\n",
    "```\n",
    "Text: \"The cat is sleeping\"\n",
    "       ↓ (Embedding Model)\n",
    "Vector: [0.23, -0.15, 0.67, ..., 0.42]  # 384 dimensions\n",
    "```\n",
    "\n",
    "**Key properties:**\n",
    "- Similar meanings → nearby vectors\n",
    "- Vector math works: \"king\" - \"man\" + \"woman\" ≈ \"queen\"\n",
    "- Learned from data, not hand-coded\n",
    "\n",
    "### Experiment 1.1: Visualize Embedding Space\n",
    "\n",
    "**Goal:** See how embeddings cluster semantically similar sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8c9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_embedding_space():\n",
    "    \"\"\"\n",
    "    Show how embeddings cluster semantically similar sentences\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load a real embedding model\n",
    "    print(\"Loading sentence-transformers model...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # 384 dimensions\n",
    "    \n",
    "    # Test sentences with known semantic clusters\n",
    "    sentences = [\n",
    "        # Cluster 1: Animals\n",
    "        \"The cat sits on the mat\",\n",
    "        \"Dogs are loyal companions\",\n",
    "        \"The bird flew over the tree\",\n",
    "        \"Lions hunt in the savannah\",\n",
    "        \n",
    "        # Cluster 2: Technology\n",
    "        \"The computer crashed again\",\n",
    "        \"Python is a great programming language\",\n",
    "        \"Artificial intelligence is the future\",\n",
    "        \"My smartphone battery is dead\",\n",
    "        \n",
    "        # Cluster 3: Food\n",
    "        \"The pizza tastes delicious\",\n",
    "        \"I love eating sushi for dinner\",\n",
    "        \"Vegetables are healthy for you\",\n",
    "        \"The cake was too sweet\",\n",
    "        \n",
    "        # Cluster 4: Emotions\n",
    "        \"I feel so happy today\",\n",
    "        \"This makes me very angry\",\n",
    "        \"She is sad about the news\",\n",
    "        \"They feel overwhelmed\",\n",
    "    ]\n",
    "    \n",
    "    # Generate embeddings (384-dimensional vectors)\n",
    "    print(\"Generating embeddings...\")\n",
    "    embeddings = model.encode(sentences)\n",
    "    print(f\"Embedding shape: {embeddings.shape}\")  # (16, 384)\n",
    "    \n",
    "    # Reduce to 2D for visualization using t-SNE\n",
    "    print(\"Reducing to 2D...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=5)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Color by cluster\n",
    "    colors = ['red'] * 4 + ['blue'] * 4 + ['green'] * 4 + ['purple'] * 4\n",
    "    labels = ['Animals'] * 4 + ['Technology'] * 4 + ['Food'] * 4 + ['Emotions'] * 4\n",
    "    \n",
    "    for i, (x, y) in enumerate(embeddings_2d):\n",
    "        plt.scatter(x, y, c=colors[i], s=200, alpha=0.6, edgecolors='black')\n",
    "        plt.annotate(\n",
    "            sentences[i], \n",
    "            (x, y),\n",
    "            xytext=(5, 5), \n",
    "            textcoords='offset points',\n",
    "            fontsize=9\n",
    "        )\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='red', label='Animals'),\n",
    "        Patch(facecolor='blue', label='Technology'),\n",
    "        Patch(facecolor='green', label='Food'),\n",
    "        Patch(facecolor='purple', label='Emotions'),\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='best')\n",
    "    \n",
    "    plt.title(\"Semantic Similarity in Embedding Space\\n(384D → 2D via t-SNE)\", fontsize=14)\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nKey Observation:\")\n",
    "    print(\"  - Sentences about animals cluster together\")\n",
    "    print(\"  - Technology terms cluster separately\")\n",
    "    print(\"  - This clustering is LEARNED, not hard-coded!\")\n",
    "    print(\"  - This is why semantic search works\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    visualize_embedding_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9fdf8",
   "metadata": {},
   "source": [
    "## Part 2: Embedding Model Comparison (Empirical)\n",
    "\n",
    "### The Landscape of Embedding Models\n",
    "\n",
    "**Common options:**\n",
    "\n",
    "| Model | Dimensions | Speed | Quality | Use Case |\n",
    "|-------|------------|-------|---------|----------|\n",
    "| all-MiniLM-L6-v2 | 384 | Fast | Good | General purpose |\n",
    "| all-mpnet-base-v2 | 768 | Medium | Better | Higher quality |\n",
    "| BAAI/bge-large-en-v1.5 | 1024 | Slow | Best | Maximum quality |\n",
    "\n",
    "**Trade-offs:**\n",
    "- Larger models = better quality, slower, more memory\n",
    "- Smaller models = faster, good enough for most cases\n",
    "\n",
    "### Experiment 2.1: Speed Benchmarks\n",
    "\n",
    "**Goal:** Measure real-world performance differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa120084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def benchmark_embedding_models():\n",
    "    \"\"\"\n",
    "    Compare speed of different embedding models\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {\n",
    "        \"tiny_fast\": \"all-MiniLM-L6-v2\",        # 384d\n",
    "        \"medium\": \"all-mpnet-base-v2\",          # 768d\n",
    "        # \"large_slow\": \"BAAI/bge-large-en-v1.5\", # 1024d (Commented out to save download time)\n",
    "    }\n",
    "    \n",
    "    # Test corpus (simulate Chatbot traces)\n",
    "    test_texts = [\n",
    "        \"User expressed anxiety about work deadlines and feeling overwhelmed\",\n",
    "        \"Bot suggested breaking down tasks into smaller steps\",\n",
    "        \"User felt relieved after discussing the plan\",\n",
    "        \"Bot reminded user to take breaks\",\n",
    "        \"Previous discussion about coping with stress and pressure\",\n",
    "    ] * 20  # 100 texts total\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"EMBEDDING MODEL SPEED BENCHMARK\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nTest corpus: {len(test_texts)} texts\")\n",
    "    print()\n",
    "    \n",
    "    for name, model_name in models.items():\n",
    "        print(f\"Testing {name} ({model_name})...\")\n",
    "        \n",
    "        # Load model\n",
    "        start_load = time.time()\n",
    "        model = SentenceTransformer(model_name)\n",
    "        load_time = time.time() - start_load\n",
    "        \n",
    "        # Warmup\n",
    "        model.encode(\"warmup\")\n",
    "        \n",
    "        # Benchmark encoding\n",
    "        start_encode = time.time()\n",
    "        embeddings = model.encode(test_texts)\n",
    "        encode_time = time.time() - start_encode\n",
    "        \n",
    "        texts_per_sec = len(test_texts) / encode_time\n",
    "        \n",
    "        results[name] = {\n",
    "            \"load_time\": load_time,\n",
    "            \"encode_time\": encode_time,\n",
    "            \"texts_per_sec\": texts_per_sec,\n",
    "            \"dim\": embeddings.shape[1]\n",
    "        }\n",
    "        \n",
    "        print(f\"  - Load time: {load_time:.2f}s\")\n",
    "        print(f\"  - Encode time: {encode_time:.4f}s\")\n",
    "        print(f\"  - Speed: {texts_per_sec:.1f} texts/sec\")\n",
    "        print(f\"  - Dimensions: {embeddings.shape[1]}\")\n",
    "        print()\n",
    "    \n",
    "    # Comparison\n",
    "    print(\"=\" * 70)\n",
    "    print(\"COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    baseline = results[\"tiny_fast\"]\n",
    "    \n",
    "    for name, res in results.items():\n",
    "        if name == \"tiny_fast\":\n",
    "            continue\n",
    "            \n",
    "        speedup = baseline[\"texts_per_sec\"] / res[\"texts_per_sec\"]\n",
    "        print(f\"{name} is {speedup:.1f}x slower than tiny_fast\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RECOMMENDATION:\")\n",
    "    print(\"  For Chatbot trace retrieval:\")\n",
    "    print(\"    - Start with 'tiny_fast' (384d)\")\n",
    "    print(\"    - Only upgrade if retrieval quality is insufficient\")\n",
    "    print(\"    - Speed matters for real-time response\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    benchmark_embedding_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22edebb1",
   "metadata": {},
   "source": [
    "## Part 3: Domain-Specific Optimization\n",
    "\n",
    "### Applying Embeddings to Your Architecture\n",
    "\n",
    "**Current Chatbot embedding usage:**\n",
    "\n",
    "1. **Trace retrieval** (Lesson 5 gap experiments)\n",
    "   - Query: User message\n",
    "   - Corpus: Successful reasoning traces\n",
    "   - Goal: Find relevant past patterns\n",
    "\n",
    "2. **Memory search** (across 5 databases)\n",
    "   - Query: Current context\n",
    "   - Corpus: Past conversations, facts, events\n",
    "   - Goal: Retrieve relevant context\n",
    "\n",
    "### Experiment 4.1: Optimize Trace Retrieval\n",
    "\n",
    "**Goal:** Find best embedding setup for trace retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a394f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def optimize_trace_retrieval():\n",
    "    \"\"\"\n",
    "    Test different embedding models on Chatbot trace retrieval\n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate trace database\n",
    "    traces = [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"query_pattern\": \"User is stressed about work\",\n",
    "            \"approach\": \"Validate feelings -> Break down problem -> Suggest small step\",\n",
    "            \"tools_used\": [\"empathy_engine\", \"planner\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"query_pattern\": \"User wants to learn a new skill\",\n",
    "            \"approach\": \"Assess current level -> Recommend resources -> Set goal\",\n",
    "            \"tools_used\": [\"resource_finder\", \"goal_setter\"]\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"query_pattern\": \"User asks about past conversation\",\n",
    "            \"approach\": \"Search memory -> Summarize context -> Answer specific question\",\n",
    "            \"tools_used\": [\"memory_search\", \"summarizer\"]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Format traces as text for embedding\n",
    "    trace_texts = [\n",
    "        f\"Query: {t['query_pattern']}\\nApproach: {t['approach']}\\nTools: {t['tools_used']}\"\n",
    "        for t in traces\n",
    "    ]\n",
    "    \n",
    "    # Test queries (what user actually asks)\n",
    "    test_queries = [\n",
    "        \"I'm feeling stressed about my job\",              # Should match trace 0\n",
    "        \"I want to learn how to code python\",             # Should match trace 1\n",
    "        \"What did I mention last Tuesday?\",               # Should match trace 2\n",
    "    ]\n",
    "    \n",
    "    # Expected top result for each query\n",
    "    expected = [0, 1, 2]\n",
    "    \n",
    "    models_to_test = {\n",
    "        \"tiny_384d\": \"all-MiniLM-L6-v2\",\n",
    "        # \"medium_768d\": \"all-mpnet-base-v2\",\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"TRACE RETRIEVAL OPTIMIZATION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Traces: {len(traces)}\")\n",
    "    print(f\"Test queries: {len(test_queries)}\")\n",
    "    print()\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, model_path in models_to_test.items():\n",
    "        print(f\"\\n--- Testing {model_name} ---\")\n",
    "        model = SentenceTransformer(model_path)\n",
    "        \n",
    "        # Embed traces\n",
    "        trace_embeddings = model.encode(trace_texts)\n",
    "        \n",
    "        correct_count = 0\n",
    "        \n",
    "        for i, query in enumerate(test_queries):\n",
    "            query_embedding = model.encode(query)\n",
    "            \n",
    "            # Calculate similarity\n",
    "            similarities = cosine_similarity(\n",
    "                [query_embedding], \n",
    "                trace_embeddings\n",
    "            )[0]\n",
    "            \n",
    "            # Get top match\n",
    "            top_match_idx = np.argmax(similarities)\n",
    "            \n",
    "            is_correct = (top_match_idx == expected[i])\n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "                \n",
    "            print(f\"  Query: '{query}'\")\n",
    "            print(f\"    -> Matched Trace {top_match_idx} (Score: {similarities[top_match_idx]:.3f})\")\n",
    "            print(f\"    -> Correct? {is_correct}\")\n",
    "            \n",
    "        accuracy = correct_count / len(test_queries)\n",
    "        results[model_name] = accuracy\n",
    "        print(f\"  Accuracy: {accuracy:.1%}\\n\")\n",
    "    \n",
    "    # Recommendation\n",
    "    print(\"=\" * 70)\n",
    "    print(\"RECOMMENDATION FOR CHATBOT:\")\n",
    "    \n",
    "    best_model = max(results, key=results.get)\n",
    "    print(f\"  Best model: {best_model} ({results[best_model]:.1%} accuracy)\")\n",
    "    \n",
    "    if results[\"tiny_384d\"] >= 0.8:\n",
    "        print(\"\\n  ✓ Tiny model (384d) performs well - use it!\")\n",
    "        print(\"    - Good enough quality\")\n",
    "    else:\n",
    "        print(\"\\n  ⚠ Consider upgrading embedding model\")\n",
    "        print(\"    - Try medium (768d) or fine-tune\")\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimize_trace_retrieval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e3477",
   "metadata": {},
   "source": [
    "## Summary & Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Embeddings = Semantic meaning in vector space**\n",
    "   - Not just word overlap\n",
    "   - Capture similarity, synonyms, paraphrases\n",
    "\n",
    "2. **Model Selection Trade-offs**\n",
    "   - 384d: Fast, good enough for most cases\n",
    "   - 1024d: 3x slower, ~15% better\n",
    "\n",
    "3. **Chatbot Specific**\n",
    "   - Trace retrieval depends on embeddings\n",
    "   - Upgrade only if retrieval is bottleneck\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**Start here:**\n",
    "- Use `all-MiniLM-L6-v2` (384d)\n",
    "- Fast, proven, good baseline\n",
    "\n",
    "**Upgrade if:**\n",
    "- Retrieval quality < 80%\n",
    "- Queries returning wrong traces\n",
    "- Speed not critical"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
